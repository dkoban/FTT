{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import api_wrapper as api\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query user profile info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = pd.read_csv(\"/Users/dankoban/Documents/EM6586_DB_Management/bearer_token.csv\")\n",
    "os.environ[\"BEARER_TOKEN\"] = token['token'][0]\n",
    "\n",
    "seed_accounts = ['NFL']\n",
    "seed_account_info = api.get_users(usernames=seed_accounts)                    \n",
    "seed_account_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for posting activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = api.get_user_activity(usernames=seed_accounts, record_count = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tweets.\n",
    " sort_values('like_count', ascending = False).\n",
    " filter(['author_screen_name', 'text', 'conversation_id', \n",
    "         'like_count', 'reply_count', 'retweet_count', \n",
    "         'referenced_tweet_type']).\n",
    " head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Most Liked URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_liked_urls = tweets['id'][tweets['like_count'] >= 10000].tolist()\n",
    "len(most_liked_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = api.get_user_activity_simple('cnn', token = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el = api.extract_el(tweets)\n",
    "urls = el[el['edge_type'] == 'url'].rename(columns={'to': 'url'})\n",
    "urls[['status_id', 'url']][urls['status_id'].isin(most_liked_urls)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = el[el['edge_type'] == 'hashtag'].rename(columns={'to': 'hashtag'})\n",
    "top_hashtags = (hashtags.groupby('hashtag').\n",
    "                agg({'status_id': len}).                  \n",
    "                reset_index().\n",
    "                rename(columns={'hashtag': 'hashtag', 'status_id': 'hashtag_count'}).\n",
    "                sort_values('hashtag_count', ascending = False).\n",
    "                reset_index(drop = True).\n",
    "                query('hashtag_count >= 5'))\n",
    "top_hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets by hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "tweets_by_hashtag = (hashtags[['hashtag', 'status_id']][hashtags['hashtag'].isin(top_hashtags.hashtag)].             \n",
    "                     merge(tweets[['id','text']], how='left', left_on='status_id', right_on='id').\n",
    "                     filter(['hashtag', 'text']).\n",
    "                     sort_values('hashtag').\n",
    "                     reset_index(drop=True))\n",
    "tweets_by_hashtag.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tweets_by_hashtag['text'] = tweets_by_hashtag['text'].apply(lambda x: re.sub(r'http\\S+', ' ', x))\n",
    "tweets_by_hashtag['text'] = tweets_by_hashtag['text'].apply(lambda x: re.sub(r'@\\S+', ' ', x))\n",
    "tweets_by_hashtag['text'] = tweets_by_hashtag['text'].apply(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "tweets_by_hashtag.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool tweets by hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_df = tweets_by_hashtag.groupby(\"hashtag\")[\"text\"].apply(lambda x: \"\".join(x)).reset_index()\n",
    "pooled_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a corpus and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from gensim import corpora, models, matutils\n",
    "\n",
    "texts = pooled_df['text'].tolist()\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', \n",
    "                             ngram_range = (1,1), \n",
    "                             token_pattern=\"\\\\b[a-z][a-z][a-z]+\\\\b\",\n",
    "                             max_df=1.0, \n",
    "                             min_df=3,\n",
    "                             max_features=1000000) \n",
    "\n",
    "vectorizer.fit(texts)\n",
    "doc_word = vectorizer.transform(texts).transpose()\n",
    "corpus = matutils.Sparse2Corpus(doc_word)\n",
    "    \n",
    "word2id = dict((v, k) for v, k in vectorizer.vocabulary_.items())\n",
    "id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
    "\n",
    "dictionary = corpora.Dictionary()\n",
    "dictionary.id2token = id2word\n",
    "dictionary.token2id = word2id\n",
    "    \n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "cm_values = []\n",
    "for k in range(5,15):\n",
    "    os.environ.update({'MALLET_HOME':r'/Users/dankoban/mallet-2.0.8/'})\n",
    "\n",
    "    lda = LdaMallet(mallet_path = '/Users/dankoban/mallet-2.0.8/bin/mallet', \n",
    "                    corpus=corpus, num_topics=k, id2word=dictionary, \n",
    "                    workers = 20, iterations = 500, random_seed = 1)\n",
    "\n",
    "    cm = CoherenceModel(model=lda, corpus=corpus, coherence='u_mass')\n",
    "    coherence_val = cm.get_coherence()\n",
    "    print(str(k) + \": \" + str(coherence_val))\n",
    "    cm_values.append(coherence_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame({'k': range(5,15), 'val': cm_values})\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMallet(mallet_path = '/Users/dankoban/mallet-2.0.8/bin/mallet', \n",
    "                corpus=corpus, num_topics=12, id2word=dictionary, \n",
    "                workers = 20, iterations = 500, random_seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_results = lda[corpus]\n",
    "\n",
    "corpus_topics = [sorted(topics, \n",
    "                        key=lambda record: -record[1])[0] for topics in tm_results]\n",
    "\n",
    "topics = [[(term, round(wt, 3)) for term, wt in lda.show_topic(n, topn=10)] \n",
    "                                for n in range(0, lda.num_topics)]\n",
    "\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic]) for topic in topics], \n",
    "                         columns = ['Terms per Topic'], \n",
    "                         index=['Topic'+str(t) for t in range(1, lda.num_topics+1)] )\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate topic quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = CoherenceModel(model=lda, corpus=corpus, coherence='u_mass')\n",
    "cm.get_coherence_per_topic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tokens = pd.read_csv(\"/Users/dankoban/Desktop/api_keys/tokens.csv\")\n",
    "awis_token = tokens['key'][tokens['name'] == 'awis_token'].tolist()[0]\n",
    "awis_access_id = tokens['key'][tokens['name'] == 'awis_access_id'].tolist()[0]\n",
    "twitter_bearer_token = tokens['key'][tokens['name'] == 'twitter_academic_bearer_token'].tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query news sites for Alexa rank\n",
    "\n",
    "https://www.alexa.com/popular-articles/public-health#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataUrl': 'cnn.com/', 'Rank': '73'}\n",
      "{'DataUrl': 'dailywire.com/', 'Rank': '3001'}\n",
      "{'DataUrl': 'publichealth.lacounty.gov/', 'Rank': '4333'}\n"
     ]
    }
   ],
   "source": [
    "from util import get_alexa_rank\n",
    "\n",
    "domains = ['cnn.com', 'dailywire.com', 'publichealth.lacounty.gov']\n",
    "for domain in domains:\n",
    "    print(get_alexa_rank(domain, api_key = awis_token, access_id = awis_access_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Twitter \n",
    "\n",
    "https://developer.twitter.com/en/docs/twitter-api/early-access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>created_at</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>listed_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9130702</td>\n",
       "      <td>starsandstripes</td>\n",
       "      <td>Stars and Stripes</td>\n",
       "      <td>Stars and Stripes provides independent news an...</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>2007-09-27T19:58:13.000Z</td>\n",
       "      <td>251314.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>146891.0</td>\n",
       "      <td>3538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id         username               name  \\\n",
       "0  9130702  starsandstripes  Stars and Stripes   \n",
       "\n",
       "                                         description         location  \\\n",
       "0  Stars and Stripes provides independent news an...  Washington D.C.   \n",
       "\n",
       "                 created_at  followers_count  following_count  tweet_count  \\\n",
       "0  2007-09-27T19:58:13.000Z         251314.0            477.0     146891.0   \n",
       "\n",
       "   listed_count  \n",
       "0        3538.0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import api_wrapper as api\n",
    "import os\n",
    "\n",
    "os.environ[\"BEARER_TOKEN\"] = twitter_bearer_token\n",
    "\n",
    "seed_accounts = ['starsandstripes']\n",
    "seed_account_info = api.get_users(usernames=seed_accounts)                    \n",
    "seed_account_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': '1374747080602828806',\n",
       "   'public_metrics': {'retweet_count': 22,\n",
       "    'reply_count': 6,\n",
       "    'like_count': 24,\n",
       "    'quote_count': 4},\n",
       "   'text': 'Russia outsources disinformation efforts to foreign troll farms\\n https://t.co/BKrOO6knnh',\n",
       "   'author_id': '9130702',\n",
       "   'conversation_id': '1374747080602828806'}]}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rehydrate_status_ids(ids, token = 0):\n",
    "    # authenticate with end point\n",
    "    bearer_token = os.environ.get(\"BEARER_TOKEN\")\n",
    "    tweet_fields = \"tweet.fields=author_id,conversation_id,public_metrics\"\n",
    "    ids = [str(id) for id in ids]\n",
    "    ids = \"ids=\" + \",\".join(ids)        \n",
    "    url = \"https://api.twitter.com/2/tweets?{}&{}\".format(ids, tweet_fields)\n",
    "    \n",
    "    # submit GET request - submit a query to the API      \n",
    "    response = requests.request(\"GET\", url, \n",
    "                                headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)})   \n",
    "    \n",
    "    return response\n",
    "\n",
    "r = rehydrate_status_ids(ids = ['1374747080602828806'])\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': '1374754758183985157',\n",
       "   'text': '@starsandstripes Biden/Harris used Indian troll farms to spread theirs ... but y‚Äôall aren‚Äôt ready to talk about the manufactured consent in the US'},\n",
       "  {'id': '1374752841252880386',\n",
       "   'text': '@starsandstripes They now have a mutual agreement with CNN to counter the internal propaganda for China'},\n",
       "  {'id': '1374751696497283073',\n",
       "   'text': '@starsandstripes While we are at it\\nalso a quantitative number\\nthat are State Dept/USAID/CIA funded SM accounts\\nlinked to troll farms (paid to tweet/like)\\nBoth inside US and foreign'},\n",
       "  {'id': '1374750663788400643',\n",
       "   'text': \"@starsandstripes Now do DNC funded type\\nACORN foreign paid trollops\\nand their farms in China, Africa, EU, and India\\nI'll wait\"},\n",
       "  {'id': '1374749150403776516',\n",
       "   'text': '@starsandstripes And this is new? Been happening since the Soviet Cold War.'},\n",
       "  {'id': '1374748906085515270',\n",
       "   'text': '@starsandstripes Nah!  America government are simply clowns! America is weak and fragile - ya know - Dont hurt Americas feelings. Does WAR have feelings?'},\n",
       "  {'id': '1374747470442430464',\n",
       "   'text': '@starsandstripes and 75m Americans are STILL buying in... including active duty militaryü§¶\\u200d‚ôÄÔ∏è #WakeUpAmerica'}],\n",
       " 'meta': {'newest_id': '1374754758183985157',\n",
       "  'oldest_id': '1374747470442430464',\n",
       "  'result_count': 7}}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rehydrate_conversation(conversation_id):\n",
    "    # authenticate with end point\n",
    "    bearer_token = os.environ.get(\"BEARER_TOKEN\")\n",
    "    tweet_fields = \"tweet.fields=lang,author_id,conversation_id\"\n",
    "    url = 'https://api.twitter.com/2/tweets/search/recent?query=conversation_id:' + conversation_id\n",
    "    \n",
    "    # submit GET request - submit a query to the API      \n",
    "    response = requests.request(\"GET\", url, \n",
    "                                headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)})   \n",
    "    \n",
    "    return response\n",
    "\n",
    "r = rehydrate_conversation(conversation_id = '1374747080602828806')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': '1374770808896196608',\n",
       "   'text': 'RT @starsandstripes: Russia outsources disinformation efforts to foreign troll farms\\n https://t.co/BKrOO6knnh'},\n",
       "  {'id': '1374770278702669832',\n",
       "   'text': 'Russia outsources disinformation efforts to foreign troll farms\\n\\nhttps://t.co/sVGjAs4cX6'},\n",
       "  {'id': '1374765785621614597',\n",
       "   'text': 'RT @starsandstripes: Russia outsources disinformation efforts to foreign troll farms\\n https://t.co/BKrOO6knnh'},\n",
       "  {'id': '1374764428143386627',\n",
       "   'text': 'RT @DFRLab: \"Governments and their spy agencies launching influence operations against their adversaries... are increasingly turning to com‚Ä¶'},\n",
       "  {'id': '1374762930449784833',\n",
       "   'text': 'RT @DFRLab: \"Governments and their spy agencies launching influence operations against their adversaries... are increasingly turning to com‚Ä¶'},\n",
       "  {'id': '1374762640522813441',\n",
       "   'text': 'RT @starsandstripes: Russia outsources disinformation efforts to foreign troll farms\\n https://t.co/BKrOO6knnh'},\n",
       "  {'id': '1374753328966496256',\n",
       "   'text': 'RT @starsandstripes: Russia outsources disinformation efforts to foreign troll farms\\n https://t.co/BKrOO6knnh'},\n",
       "  {'id': '1374753167913725957',\n",
       "   'text': 'RT @starsandstripes: Russia outsources disinformation efforts to foreign troll farms\\n https://t.co/BKrOO6knnh'},\n",
       "  {'id': '1374751937787269122',\n",
       "   'text': 'RT @starsandstripes: Russia outsources disinformation efforts to foreign troll farms\\n https://t.co/BKrOO6knnh'},\n",
       "  {'id': '1374751891360473091',\n",
       "   'text': 'RT @starsandstripes: Russia outsources disinformation efforts to foreign troll farms\\n https://t.co/BKrOO6knnh'}],\n",
       " 'meta': {'newest_id': '1374770808896196608',\n",
       "  'oldest_id': '1374751891360473091',\n",
       "  'result_count': 10,\n",
       "  'next_token': 'b26v89c19zqg8o3fosqspauvo935hatgyp4irmw3zdpj1'}}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_retweets(conversation_id):\n",
    "    # authenticate with end point\n",
    "    bearer_token = os.environ.get(\"BEARER_TOKEN\")\n",
    "    tweet_fields = \"tweet.fields=lang,author_id,conversation_id\"\n",
    "    url = 'https://api.twitter.com/2/tweets/search/recent?query=Russia outsources disinformation efforts to foreign troll farms\\n'\n",
    "    \n",
    "    # submit GET request - submit a query to the API      \n",
    "    response = requests.request(\"GET\", url, \n",
    "                                headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)})   \n",
    "    \n",
    "    return response\n",
    "\n",
    "r = find_retweets(conversation_id = '1374747080602828806')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'lang': 'en',\n",
       "   'created_at': '2021-03-24T16:30:27.000Z',\n",
       "   'text': 'PHP Interactive shell open when run any command in Command prompt https://t.co/h3ycb59LKe #php #command #commandprompt https://t.co/mLaLewHJC6',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374760533325455360'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T16:25:25.000Z',\n",
       "   'text': 'Push one branch to another while ignoring a file in github https://t.co/9KGq1qKAhl #github #git #azuredevops https://t.co/sDE23vY3Vb',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374759267161477123'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T16:20:23.000Z',\n",
       "   'text': 'Adding ST_Transform in a PL/pgSQL function https://t.co/JhqtdFyVPv #postgresql #postgis #plpgsql #coordinatetransformation https://t.co/ZGalnyBGnm',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374758000850796551'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T16:15:21.000Z',\n",
       "   'text': 'Is it legal to create a null rvalue reference in a constexpr function? https://t.co/0IME0Licmk #rvalue #rvaluereference #templates #cpp https://t.co/gNhH4JOEP3',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374756734246457345'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T16:10:20.000Z',\n",
       "   'text': 'SwiftUI DatePicker day of week language https://t.co/rPXA9Acj2y #swiftui #datepicker https://t.co/woDinZN7iE',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374755468795609089'},\n",
       "  {'lang': 'de',\n",
       "   'created_at': '2021-03-24T16:05:18.000Z',\n",
       "   'text': 'RPY2 3.3.5 Errors on import https://t.co/upKg4v1SpK #pycharm #python #rpy2 https://t.co/MskSeFsS0b',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374754203097239552'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T16:00:16.000Z',\n",
       "   'text': 'AWS S3 Get cli command line from each operation done by GUI https://t.co/blpj4EGMqs #amazonwebservices #amazons3 #awscli https://t.co/xPvCgjaiqU',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374752935482171403'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:55:14.000Z',\n",
       "   'text': 'Datastage commands to configure JSON parser dynamically https://t.co/CastF36W29 #datastage #json https://t.co/Z69FeCSpLw',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374751668601040897'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:50:12.000Z',\n",
       "   'text': 'Lua Table - Search for Items that starts with an Letter https://t.co/y9P0XkZ6Wv #lua #luatable https://t.co/CWg9fKA6Ti',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374750403267600394'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:49:06.000Z',\n",
       "   'text': \"Most Popular #Technologies...\\n\\nJavaScript has maintained it's stronghold as the most commonly used programming language.\\n\\nSource: StackOverFlow\\n\\nhttps://t.co/INpG5rdi0j\\n\\n#Programming #Scripting  #MarkupLanguages https://t.co/KMYsSRiT3u\",\n",
       "   'author_id': '1903449175',\n",
       "   'id': '1374750126141435907'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:45:10.000Z',\n",
       "   'text': 'How do I set up a unban command the right way? https://t.co/ETsK4rCAEf #sublimetext #python #discord #discordpy https://t.co/hxjo1DGejt',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374749138076770307'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:40:08.000Z',\n",
       "   'text': 'React navigation drawer https://t.co/rGUUKqaTqr #reactnavigationdrawer #reactnavigation #reactnative https://t.co/q5HsfDBo7F',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374747872021872640'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:35:07.000Z',\n",
       "   'text': 'classList.remove() peforms worse than className string manipulation https://t.co/quzPrDCfh1 #browser #javascript https://t.co/d0ZyNsPBGs',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374746606965297154'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:30:05.000Z',\n",
       "   'text': \"How to fix: AttributeError: 'module' object has no attribute 'BluetoothSocket' https://t.co/cvXFGRLRKZ #arduino #kivy #python https://t.co/qLfzCOivn1\",\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374745341069815809'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:25:03.000Z',\n",
       "   'text': 'Focus and selection from tk entry to ttk treeview with binding key https://t.co/evc8iNMwqe #python #ttk #treeview https://t.co/WG3xIlKJBT',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374744074297749507'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:20:01.000Z',\n",
       "   'text': 'Bind to button function qlik js extension https://t.co/L3sCwJVKAq #angularjs #javascript #qliksense https://t.co/9s0pkZrgGG',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374742808796532737'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:18:04.000Z',\n",
       "   'text': 'Typo3 Backend HTML Element - Format value wrong https://t.co/Hy0R9xzpbR https://t.co/ZLPhC5athH',\n",
       "   'author_id': '373225113',\n",
       "   'id': '1374742318398410756'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:15:00.000Z',\n",
       "   'text': 'How to parse weather data from NASA API https://t.co/HmaiZ3mO1a #swift #parsing #json https://t.co/llfBABVqkI',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374741543211446273'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:09:58.000Z',\n",
       "   'text': \"Why JSON object isn't being stored properly? https://t.co/YGKkKRtBxA #reactjs #localstorage #javascript https://t.co/x3AudTnfI5\",\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374740277458518017'},\n",
       "  {'lang': 'en',\n",
       "   'created_at': '2021-03-24T15:04:56.000Z',\n",
       "   'text': 'VSCode PHP - create function if not exist https://t.co/4OiJOmVrED #php #visualstudiocode https://t.co/iqrrKxbHLG',\n",
       "   'author_id': '1098709061334429696',\n",
       "   'id': '1374739012229926918'}],\n",
       " 'meta': {'newest_id': '1374760533325455360',\n",
       "  'oldest_id': '1374739012229926918',\n",
       "  'result_count': 20,\n",
       "  'next_token': 'b26v89c19zqg8o3fosqspauafhlrpfpmcxydg8jn92av1'}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "def search_url(url, token = 0):\n",
    "    # authenticate with end point\n",
    "    bearer_token = os.environ.get(\"BEARER_TOKEN\")\n",
    "    \n",
    "    # query profile info to get a user_id\n",
    "    #user_info = get_users(username)\n",
    "    #user_id = user_info['user_id'][0]\n",
    "    \n",
    "    # generate query string    \n",
    "    # 'https://api.twitter.com/2/tweets/search/all?query=caturday%20has:images%20-is:retweet&tweet.fields=created_at,author_id,lang&max_results=20'\n",
    "    # 'url:stackoverflow.com'\n",
    "    # https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n",
    "    if token == 0: \n",
    "        url =  'https://api.twitter.com/2/tweets/search/all?query=' + url + '%20has:images%20-is:retweet&tweet.fields=created_at,author_id,lang&max_results=20'\n",
    "    else:\n",
    "        url =  'https://api.twitter.com/2/tweets/search/?query=' + url + '/tweets?tweet.fields=conversation_id,in_reply_to_user_id,created_at,author_id,entities,public_metrics,geo,lang,referenced_tweets&max_results=100&pagination_token=' + token    \n",
    "    \n",
    "    # submit GET request - submit a query to the API      \n",
    "    response = requests.request(\"GET\", url, \n",
    "                                headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)})   \n",
    "    \n",
    "    return response\n",
    "\n",
    "r = search_url(url = 'url:stackoverflow.com', token = 0)\n",
    "r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'result_count': 0}}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.twitter.com/2/tweets/search/all?query=http%3A%2F%2Fwww.theguardian.com%2Fhealthcare-network%2Fviews-from-the-nhs-frontline%2F2015%2Fjul%2F13%2Fwasting-gps-time-no-i-cant-prescribe-you-new-shoes&tweet.fields=created_at,author_id,lang&max_results=20'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = 'http%3A%2F%2Fwww.theguardian.com%2Fhealthcare-network%2Fviews-from-the-nhs-frontline%2F2015%2Fjul%2F13%2Fwasting-gps-time-no-i-cant-prescribe-you-new-shoes'\n",
    "q\n",
    "'https://api.twitter.com/2/tweets/search/all?query=' + q +  '&tweet.fields=created_at,author_id,lang&max_results=20'\n",
    "'https://twitter.com/i/api/1.1/search/typeahead.json?q=http%3A%2F%2Fwww.theguardian.com%2Fhealthcare-network%2Fviews-from-the-nhs-frontline%2F2015%2Fjul%2F13%2Fwasting-gps-time-no-i-cant-prescribe-you-new-shoes&src=search_box&result_type=events%2Cusers%2Ctopics'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
